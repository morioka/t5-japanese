
# t5ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

ä»Šã¾ã§ã®åçœã‹ã‚‰

- ç°¡å˜ã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™æ®µéšã§å…¥åŠ›ã‚’æ•´å½¢ã—ã¦ãŠãã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¾¼ã¿ã®çŠ¶æ…‹
  - TODOï¼šã€€ã‚­ãƒ¼ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŒ‡å®šã§ãã‚Œã°ã€ä»»æ„ã®å½¢ã«ã§ãã‚‹ã ã‚ã†
- ãƒ‡ãƒ¼ã‚¿æ•´å½¢ã¯ã€æ”¹è¡Œé™¤å» + NFKCæ­£è¦åŒ– + neologdn
  - å°æ–‡å­—ãã‚ãˆã—ãªã„
    - å›ºæœ‰åè©ã§ãªã‘ã‚Œã°ã€è£½å“åã§ãªã‘ã‚Œã°ã€å°æ–‡å­—ãã‚ãˆã—ã¦ã‚‚ã‚ˆã„ãŒ
  - TODO: ã‹ã£ã“ã®é™¤å»ã¯ã‚„ã£ã¦ã‚ˆã„ã‹ã‚‚
- å…¥å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®å¤‰æ›´ã€‚
  - TSVã¯ãã®ã¾ã¾
  - æ—§å½¢å¼ã¯"{question}\t{answer}\t{context}"
  - å½¢å¼ã¯"{QA_ID}\tquestion: {question} context: {context}\t{answer}"
    - QA_IDã‚’ã‚­ãƒ¼ã¨ã—ãŸã„

## ã‚³ãƒ¼ãƒ‰

- download.sh   : ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- prepare_jsquad.py : JGLUE/JSQuAD ã‚’ qaç”¨TSVã«åŠ å·¥
  - qid, "question: {question} context: {passage}", answer
- train.py
- predict.py : text2text-generation ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å‘¼ã¶ã ã‘


## åˆ©ç”¨

â€»æœªå®Ÿè£…ã®ã‚‚ã®ã‚ã‚Š

JSQuAD QA

```
'question: {question} context: {context}' -> '{answer}'
```

```bash
download.sh
python prepare_jsquad.py
python train.py --do_train --do_eval \
  --model_name_or_path sonoisa/t5-base-japanese 
```

JSQuAD AQG

```
'answer: {answer} context: {context}' -> '{question}'
```

```bash
download.sh
python prepare_jsquad_aqg.py
python train.py --do_train --do_eval \
  --model_name_or_path sonoisa/t5-base-japanese \
  --output_dir model_jsquad_aqg \
  --data_dir data_jsquad_aqg \
  --max_target_length 128
```


JSQuAD AQG-HL

```
'c1 c2 ... <hl> a1 ... a|A| <hl> ... c|C|' -> '{question}'
```

```bash
download.sh
python prepare_jsquad_aqg.py  # ä¸­ã® with_highlight=True
python train.py --do_train --do_eval \
  --model_name_or_path sonoisa/t5-base-japanese \
  --output_dir model_jsquad_aqg_hl \
  --data_dir data_jsquad_aqg_hl \
  --max_target_length 128
```



quiz  AQG

```
'answer: {answer} context: {context}' -> '{question}'
```

```bashd
python prepare_quiz_aqg.py
python train.py --max_target_length 128
```

quiz  AQG-HL    
    - https://huggingface.co/p208p2002/t5-squad-qg-hl
    - https://github.com/patil-suraj/question_generation#answer-aware-question-generation

    ãƒã‚¤ãƒ©ã‚¤ãƒˆå½¢å¼ã€‚åŒºåˆ‡ã‚Œã‚‹ï¼Ÿ
    æ–‡ã‚’<SEP>ã§åŒºåˆ‡ã‚‹? æ–‡ã”ã¨ã«attention_maskã‚’å¤‰ãˆã‚‹?
    <hl> 42 <hl> is the answer to life, the universe and everything.


```
'c1 c2 ... <hl> a1 ... a|A| <hl> ... c|C|' -> '{question}'
```

è§£ç­”èªå¥éƒ¨åˆ†ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹ã€‚ãƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚ŒãŸå‘¨è¾ºæ–‡è„ˆã«åŸºã¥ã„ã¦ç”Ÿæˆã™ã‚‹ã‚ˆã†èª˜å°ã™ã‚‹?

```bash
python prepare_quiz_aqg_hl.py
python train.py --max_target_length 128
```

3/17 ç¾çŠ¶ã€‚fp16=Trueã ã¨nanã€‚fp16=Falseã ã¨ã‚ˆã„ã€‚


## è©•ä¾¡

TODO:
- sumevalã‚’ä½¿ã£ã¦ã„ãŸãŒã€huggingface datasets metrics ã‹ huggingface evaluateã‚’ä½¿ã†ã‚ˆã†ã«ã€‚
- ãƒˆãƒ¼ã‚¯ãƒ³ã¾ãŸã¯å˜èªå˜ä½ã§ã®æ¯”è¼ƒãŒå¿…è¦ã§ã€T5tokenizerã€mecab, sudachi(A? B? C?)ã®ãã‚Œãã‚Œã§åŒºåˆ‡ã£ã¦æ¯”è¼ƒã™ã‚‹ã€‚

- `model_name_or_path` ã§ãªã `output_dir` ã‚’èª­ã‚€
- ExactMatch ã¨ sacrebleu[ja]ã«ã‚ˆã‚‹ BLEU

```bash
python train.py --do_eval --output_dir model
```

### è©•ä¾¡æŒ‡æ¨™

- EM (ExactMatch):  æ–‡å­—åˆ—ãƒ™ãƒ¼ã‚¹
- BLUE:   mjpost/sacrebleu + mecab-ipadic
- ROUGE:  neulab/compare-mt + mecab-ipadic 

## æ¨è«–

â€» AQGå°‚ç”¨

```
'answer: {answer} context: {context}' -> '{question}'
```

```bash
python generate.py

python generate.py --answer ç”²åºœå¸‚ --context å±±æ¢¨çœŒã®çœŒåºæ‰€åœ¨åœ°ã¯ç”²åºœå¸‚ã§ã™ã€‚
#å±±æ¢¨çœŒã®çœŒåºæ‰€åœ¨åœ°ã¯ã©ã“ã§ã™ã‹?
python generate.py --answer ç”²åºœå¸‚ --context å±±æ¢¨çœŒã®çœŒåºæ‰€åœ¨åœ°ã¯ç”²åºœå¸‚ã§ã™ã€‚ --bad_words å±±æ¢¨ å±±æ¢¨çœŒ
#ä¸­éƒ¨åœ°æ–¹ã®çœŒåºæ‰€åœ¨åœ°ã¯ã©ã“ã§ã™ã‹?
```

## ç’°å¢ƒè¨­å®š

```bash
# python-3.10.8
pip install -qU pip wheel
pip install -qU neologdn pandas numpy scikit-learn tqdm classopt
pip install -qU torch torchtext torchvision torchaudio
pip install -qU transformers pytorch-lightning sentencepiece protobuf==3.20.0
pip install -qU sacrebleu[ja]
pip install -qU compare_mt
pip install -qU mecab-python3 fugashi ipadic
pip install -qU spacy ja_ginza
pip install -qU datasets evaluate
```

```
Package                  Version
------------------------ ----------
classopt                 0.2.1
compare-mt               0.2.10
fugashi                  1.2.1
ginza                    5.1.2
ipadic                   1.0.0
ja-ginza                 5.1.2
mecab-python3            1.0.5
neologdn                 0.5.1
numpy                    1.24.2
pandas                   1.5.3
pip                      23.0.1
protobuf                 3.20.0
pytorch-lightning        2.0.0
scikit-learn             1.2.2
sentencepiece            0.1.97
spacy                    3.4.4
torch                    2.0.0
torchaudio               2.0.1
torchtext                0.15.1
torchvision              0.15.1
tqdm                     4.65.0
transformers             4.27.1
wheel                    0.40.0
```


## å±¥æ­´

- 3/16  å…¨é¢çš„ã«æ›¸ãç›´ã—
- 3/17  omegaconfã¨argparseä½µç”¨ã‹ã‚‰ omegaconfå˜ä½“ã¸ã€‚ã•ã‚‰ã«classopt
  - classoptã®å ´åˆã€notebookãªã©ã‹ã‚‰ã®åˆ©ç”¨ãŒä¸å¯?
- 3/20  bleu, rogue æ›¸ãç›´ã—

## TODO

- pytorch_lightningã‹ã‚‰è„±å´ã€‚ç´ ç›´ãªãƒ«ãƒ¼ãƒ—ã«å¤‰æ›´ã™ã‚‹ã€‚
  - æå¤±ã‚’è‡ªç”±ã«å®šç¾©ã§ãã‚‹ã‚ˆã†ã«
  - ã“ã‚Œã«ãªã‚‰ã† https://github.com/hppRC/bert-classification-tutorial
- ã„ãã¤ã‹ä¸è¶³ã®ã¨ã“ã‚ãŒã‚ã‚Šãã†
  - sonoisaã ã‘ã§ãªãpatil-surajã®ã“ã‚Œã‹ã€‚ã“ã‚Œã‚’ã‚‚ã¨ã«ã™ã‚‹ã€‚
    - https://github.com/patil-suraj/question_generation
    - https://github.com/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb
- best (== val_lossæœ€å°)ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã‚ˆã†ã€‚è©•ä¾¡ã§ã‚‚ãã‚Œã‚’ç”¨ã„ã‚‹ã‚ˆã†
  - https://github.com/hppRC/bert-classification-tutorial/blob/main/src/train.py


- æ¸ˆ)ROUGEã®å®Ÿè£…ã¨
- æ™®é€šã®ãƒ«ãƒ¼ãƒ—ã§æå¤±ã‚’ç”Ÿã«å‡ºã™ã¨ã“ã‚ã ãªã€‚

## ãƒãƒ«ã‚·ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³

- ç°¡å˜åŒ–ã®ãŸã‚ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¯ç”Ÿæˆæ–‡ã«å‡ºç¾ã™ã‚‹èªå¥ã®ã†ã¡ã§åŸæ–‡ã¾ãŸã¯åŸæ–‡ç« ã«ã¯å‡ºç¾ã—ãªã„èªå¥ã¨å®šç¾©ã™ã‚‹ã€‚
- è¨€ã„æ›ãˆã‚„è¡¨è¨˜ã‚†ã‚Œã®å ´åˆã€ãƒãƒ«ã‚·ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¿ãªã™ã€‚ã•ã‚‚ãªãã°äº‹å‰ä¿®æ­£ã™ã¹ãã€‚
- èƒŒæ™¯çŸ¥è­˜ãŒã‚ã‚Œã°å•é¡Œãªã„ã¨åˆ¤æ–­ã§ãã‚‹å ´åˆã§ã‚‚ã€ãƒãƒ«ã‚·ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¿ãªã™ã€‚ã•ã‚‚ãªãã°äº‹å‰ä¿®æ­£ã™ã¹ãã€‚
- å†…å®¹èªã«é™å®šã™ã‚‹ã®ãŒæœ›ã¾ã—ã„ã€‚æ©Ÿèƒ½èªã¯å¯¾è±¡ã¨ã™ã¹ãã§ãªãã€å¯¾è±¡ã¨ã—ã¦ã‚‚ä»•æ–¹ãªã„ã ã‚ã†ã€‚
  - æ©Ÿèƒ½èªã«ã‚ˆã£ã¦æ–‡æ„ãŒåè»¢ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã ã‚ã†ãŒã€ã“ã“ã§ã¯æ°—ã«ã—ãªã„ã€‚
- ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§ã¿ã‚‹ã€‚ãƒˆãƒ¼ã‚«ãƒŠã‚¤ã‚¶ã¯ mecab ã¾ãŸã¯ GiNZA(sudachi)ã€‚

```python
import spacy

nlp = spacy.load('ja_ginza')

def check_hallucination(candidate, reference, stop_words=[]):
  doc_c = nlp(candidate)
  doc_r = nlp(reference)

  tok_c = [i.text for i def checkdedefdin doc_c]
  tok_r = [i.text for i in doc_r]

  hallucination = set(tok_c) - set(tok_r)

  # stop_wordsã«å«ã¾ã‚Œã‚‹èªã¯ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¿ãªã•ãªã„
  # TODO: å†…å®¹èªã®ã¿ã«é™å®šã™ã‚‹ã‹ã€æ©Ÿèƒ½èªã‚’é™¤ãã‹ã€è¨˜å·ã‚’é™¤ãã‹
  if type(stop_words) is list:
    stop_words = set(stop_words)
  assert type(stop_words) is set
  hallucination = hallucination - stop_words
  
  return hallucination  

candidate = "ä»Šæ—¥ã¯ã‚ã‚‹ã„å¤©æ°—ã "  # ã€Œã‚ã‚‹ã„ã€ãŒ hallucination
reference = "ä»Šæ—¥ã¯å¤©æ°—ã "

check_hallucination(candidate="ä»Šæ—¥ã¯ã‚ã‚‹ã„å¤©æ°—ã ", reference="ä»Šæ—¥ã¯ã‚ã‚‹ã„å¤©æ°—ã ")
# > set()
check_hallucination(candidate="ä»Šæ—¥ã¯å¤©æ°—ã ", reference="ä»Šæ—¥ã¯ã‚ã‚‹ã„å¤©æ°—ã ")
# > set()
check_hallucination(candidate="ä»Šæ—¥ã¯ã‚ã‚‹ã„å¤©æ°—ã ", reference="ä»Šæ—¥ã¯å¤©æ°—ã ")
# >{'ã‚ã‚‹ã„'}
check_hallucination(candidate="ä»Šæ—¥ã¯ã‚ã‚‹ã„å¤©æ°—ã ", reference="ä»Šæ—¥ã¯ã‚ˆã„å¤©æ°—ã ")
# >{'ã‚ã‚‹ã„'}
```

# TODO 3/20

- pytorch_lightningã‹ã‚‰ã®è„±å´ã€‚å°‘ãªãã¨ã‚‚æå¤±ã‚’è‡ªç”±ã«å®šç¾©ã€‚
- æ¸ˆï¼šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•´å‚™  '[SEP]' ã®æ‰±ã„ã‚’ '[sep]' ã¨åŒæ§˜ã«ã€‚
- GPT-2ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚ã˜ã¤ã¯run_clm.pyå˜ç‹¬ã§å‹•ã‹ã›ã‚‹ã®ã§ã¯?
  - GPT-2ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•´å‚™
  - GPT-2ãƒ¢ãƒ‡ãƒ«ã›ã‚ã¦1Bã§ãã‚Œã°6Bã€‚ãã“ã«LoRAã¨RF
    - t5-baseã‚ˆã‚Šã¯å¤§ããªãƒ‘ãƒ©ãƒ¡ã‚¿ã§ä½•ã¨ã‹ã—ãŸã„ã€‚mt5ã§ã‚‚ã‚ˆã„ãŒã€‚
  - [GPT-2ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¡ä»¶ä»˜ãã§ç”Ÿæˆã—ã¦ã¿ãŸã€‚ - Qiita](https://qiita.com/m__k/items/36875fedf8ad1842b729)


## gpt

2023-03-21


- [GPT-2ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¡ä»¶ä»˜ãã§ç”Ÿæˆã—ã¦ã¿ãŸã€‚ - Qiita](https://qiita.com/m__k/items/36875fedf8ad1842b729)

transformersã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªãã¨ã‚‚ã€run_clm.pyã ã‘æŒã£ã¦ãã¦ã‚‚å‹•ã„ãŸã€‚

```bash
download.sh
#python prepare_data_jsquad_aqg_hl.py      # t5å‘ã‘hlå½¢å¼
python prepare_data_jsquad_aqg_hl_gpt.py  # t5å‘ã‘ã‹ã‚‰gptå‘ã‘ã«å¤‰æ›
python run_clm.py \
    --model_name_or_path=rinna/japanese-gpt2-medium \
    --train_file=data_jsquad_aqg_hl_gpt/train.txt \
    --validation_file=data_jsquad_aqg_hl_gpt/dev.txt  \
    --do_train \
    --do_eval \
    --num_train_epochs=10 \
    --save_steps=10000 \
    --save_total_limit=3 \
    --per_device_train_batch_size=1 \
    --per_device_eval_batch_size=1 \
    --output_dir=output_gpt/ \
    --use_fast_tokenizer=False
```

è¨“ç·´ã‚µã‚¤ã‚º=70040, ãƒãƒƒãƒã‚µã‚¤ã‚º=1 ã§ 12hä»¥ä¸Š /epochã¨è¨€ã£ã¦ãã‚‹ã€‚
å‹•ã‹ã™ã®ãŒç²¾ã„ã£ã±ã„ã€‚ã„ã‘ãã†ã¨åˆ¤æ–­ã—ãŸã‚‰ã€ã‚‚ã£ã¨å¤§ããªç’°å¢ƒã§å‹•ã‹ã•ãªã„ã¨ã€ã¾ã¨ã‚‚ã«å­¦ç¿’ã§ããªã„ã€‚

- https://twitter.com/morioka/status/1637951549015232512
  - <blockquote class="twitter-tweet"><p lang="en" dir="ltr">I&#39;ve gotten some requests about the &quot;building language models&quot; project from last year&#39;s Stanford Large Language Models class, so we&#39;re releasing it: <a href="https://t.co/UVT0Hdm0mr">https://t.co/UVT0Hdm0mr</a><br><br>The task is to finetune LMs to give them new capabilities/properties, similarly to Toolformer and Alpaca. <a href="https://t.co/RJhuKZLayI">pic.twitter.com/RJhuKZLayI</a></p>&mdash; Sang Michael Xie (@sangmichaelxie) <a href="https://twitter.com/sangmichaelxie/status/1637834223699783680?ref_src=twsrc%5Etfw">March 20, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
- [sangmichaelxie/cs324_p2: Project 2 (Building Large Language Models) for Stanford CS324: Understanding and Developing Large Language Models (Winter 2022](https://github.com/sangmichaelxie/cs324_p2)

---

å¤§ãã‚ã®ãƒ¢ãƒ‡ãƒ«ã§è¦‹ãŸã»ã†ãŒã‚ˆã„ã®ã‹ãªã€‚
Alpaca-LoRA (6B)ã§æ—¥æœ¬èªã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹è¨˜äº‹ãŒå‡ºå§‹ã‚ãŸã€‚

"""
ç­†è€…ã®ä½¿ç”¨GPUã¯RTX3080ä¸€å°ã§ã™ã€‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´ã™ã‚Œã°GPUãƒ¡ãƒ¢ãƒªãŒ12GBä»¥ä¸Šã§ã‚ã‚Œã°å˜ä¸€ã®GPUã§FineTuningãŒå¯èƒ½ã ã¨æ€ã„ã¾ã™ã€‚
""" ã¨ã„ã†è¨˜è¿°ã‚‚ã‚ã‚‹ã€‚

- https://twitter.com/morioka/status/1637933189028261890
  - <blockquote class="twitter-tweet"><p lang="ja" dir="ltr">è¨˜äº‹ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸï¼ Alpaca-loraã‚’æ—¥æœ¬èªã‚¿ã‚¹ã‚¯ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ [Python] on <a href="https://twitter.com/hashtag/Qiita?src=hash&amp;ref_src=twsrc%5Etfw">#Qiita</a> <a href="https://t.co/aQS68kt1kQ">https://t.co/aQS68kt1kQ</a></p>&mdash; toshi_456 (@tech_nichijo) <a href="https://twitter.com/tech_nichijo/status/1637420497561583616?ref_src=twsrc%5Etfw">March 19, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  - [Alpaca-loraã‚’æ—¥æœ¬èªã‚¿ã‚¹ã‚¯ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ - Qiita](https://qiita.com/toshi_456/items/280efc31950ddb083286)
- https://twitter.com/morioka/status/1637831647700848641
  - <blockquote class="twitter-tweet"><p lang="ja" dir="ltr">ã€Œæ‰‹å…ƒã§å‹•ãè»½é‡ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ—¥æœ¬èªã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã—ãŸ(Alpaca-LoRA)ã€ã¨ã„ã†è¨˜äº‹ã‚’æ›¸ã„ã¦ã¿ã¾ã—ãŸã€‚æ‰‹å…ƒã§å‹•ã‹ã›ã‚‹ã®ã¯ã™ã”ãä»Šå¾Œã®å¯èƒ½æ€§ã‚’æ„Ÿã˜ã¾ã™ã­ã€‚<a href="https://t.co/wOpTX3kJHz">https://t.co/wOpTX3kJHz</a></p>&mdash; Masa Kazama (@masa_kazama) <a href="https://twitter.com/masa_kazama/status/1637703014793510913?ref_src=twsrc%5Etfw">March 20, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  - [æ‰‹å…ƒã§å‹•ãè»½é‡ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ—¥æœ¬èªã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã—ãŸ(Alpaca-LoRA)ï½œmasa_kazamaï½œnote(https://note.com/masa_kazama/n/nabaa6dfec741)
- https://twitter.com/kun1em0n/status/1637973352777404417
  - <blockquote class="twitter-tweet"><p lang="ja" dir="ltr">æ—¥æœ¬èªã§å­¦ç¿’ã•ã›ãŸJapanese-Alpaca-LoRAã®13Bå­¦ç¿’é€”ä¸­(128ãƒˆãƒ¼ã‚¯ãƒ³ã§å­¦ç¿’)ã€‚åŒã˜å›ç­”ã‚’ç¹°ã‚Šè¿”ã™ã®ã§å‘½ä»¤ã§å·¥å¤«(1ã€2æšç›®)ã€‚512ãƒˆãƒ¼ã‚¯ãƒ³ã§å­¦ç¿’ã•ã›ãŸ7Bã¯æµæš¢ã ã‘ã©å›ç­”ã®ä¸­èº«ã¯é©å½“ãªã‚‚ã®ã‚‚ã‚ã‚Š(3æšç›®ã¯é©å½“ã€4æšç›®ã¯ã¼ã¡ã¼ã¡)ã€‚ã‚„ã¯ã‚Šå­¦ç¿’æ™‚é–“ã‹ã‹ã‚‹ã‘ã©13Bã‚’512ãƒˆãƒ¼ã‚¯ãƒ³ã§å­¦ç¿’ã•ã›ã‚‹ã®ãŒä¸€ç•ªã‹ğŸ¤” <a href="https://t.co/RrGnv2CLPB">https://t.co/RrGnv2CLPB</a> <a href="https://t.co/mDl2iU3GZP">pic.twitter.com/mDl2iU3GZP</a></p>&mdash; ã‚¯ãƒ‹ãˆã‚‚ã‚“.incğŸ¤— (@kun1em0n) <a href="https://twitter.com/kun1em0n/status/1637973352777404417?ref_src=twsrc%5Etfw">March 21, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


